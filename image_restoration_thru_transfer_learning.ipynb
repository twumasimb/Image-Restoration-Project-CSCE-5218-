{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Wmmmo5wl-fO5K0BYs6lTLqDoiGvaqMfd",
      "authorship_tag": "ABX9TyPccJHQ8ThM/HlWMEBGueFO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/twumasimb/Image-Restoration-Project-CSCE-5218-/blob/main/image_restoration_thru_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HvGP6Di-xVN"
      },
      "outputs": [],
      "source": [
        "# # Getting all the models we will be testing\n",
        "# \"\"\"\n",
        "# Old-photos to Life\n",
        "# \"\"\"\n",
        "# !git clone https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life.git\n",
        "\n",
        "# \"\"\"\n",
        "# GFPGAN\n",
        "# \"\"\"\n",
        "# !git clone https://github.com/TencentARC/GFPGAN.git\n",
        "\n",
        "# \"\"\"\n",
        "# CycleISP\n",
        "# \"\"\"\n",
        "# !git clone https://github.com/swz30/CycleISP.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bringing Old Images to Life Using VAEs"
      ],
      "metadata": {
        "id": "B5zW_W8nqHUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/Bringing-Old-Photos-Back-to-Life/\n",
        "\n",
        "# %cd Face_Enhancement/models/networks/\n",
        "# !git clone https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\n",
        "# !cp -rf Synchronized-BatchNorm-PyTorch/sync_batchnorm .\n",
        "# %cd ../../../\n",
        "\n",
        "# %cd Global/detection_models\n",
        "# !git clone https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\n",
        "# !cp -rf Synchronized-BatchNorm-PyTorch/sync_batchnorm .\n",
        "# %cd ../../\n",
        "\n",
        "# %cd Face_Detection/\n",
        "# !wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "# !bzip2 -d shape_predictor_68_face_landmarks.dat.bz2\n",
        "# %cd ../\n",
        "\n",
        "# %cd Face_Enhancement/\n",
        "# !wget https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life/releases/download/v1.0/face_checkpoints.zip\n",
        "# !unzip face_checkpoints.zip\n",
        "# %cd ../\n",
        "\n",
        "# %cd Global/\n",
        "# !wget https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life/releases/download/v1.0/global_checkpoints.zip\n",
        "# !unzip global_checkpoints.zip\n",
        "# %cd ../\n",
        "\n",
        "# !pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "8-on-DCFMvTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/\n",
        "\n",
        "# %cd GFPGAN/\n",
        "# # We use BasicSR for both training and inference\n",
        "# !pip install basicsr\n",
        "# # We use face detection and face restoration helper in the facexlib package\n",
        "# !pip install facexlib\n",
        "# # Install other depencencies\n",
        "# !pip install -r requirements.txt\n",
        "# !python setup.py develop\n",
        "# !pip install realesrgan  # used for enhancing the background (non-face) regions\n",
        "# # Now we use the V1.3 model for the demo\n",
        "# !wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P experiments/pretrained_models"
      ],
      "metadata": {
        "id": "TSZZnCrFCWvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp -r /content/drive/MyDrive/Notebooks/raw/ /content/datasets/inputs"
      ],
      "metadata": {
        "id": "5BHNZiZsCzNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EXPERIMENT 1**\n",
        "\n",
        "In This Phase, the Model goes as follows ISP ---> GFPGAN & ISP ---> VAE"
      ],
      "metadata": {
        "id": "W3QcveQo-Evh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ISP ---> VAE**"
      ],
      "metadata": {
        "id": "zOs8j1IeC8D3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dealing with clean data from ISP\n",
        "import os\n",
        "\n",
        "%cd /content/datasets/\n",
        "input_folder = \"inputs/clean\"\n",
        "basepath = os.getcwd()\n",
        "input_path = os.path.join(basepath, input_folder)\n",
        "\n",
        "%cd /content/datasets/outputs/exp1/\n",
        "output_folder = \"vae-clean\"\n",
        "basepath = os.getcwd()\n",
        "output_path = os.path.join(basepath, output_folder)\n",
        "os.mkdir(output_path)\n",
        "\n",
        "%cd /content/Bringing-Old-Photos-Back-to-Life\n",
        "!python run.py --input_folder /content/datasets/inputs/clean/ --output_folder /content/datasets/outputs/exp1/vae-clean/ --GPU -1\n",
        "\n",
        "# Dealing with Raw Data\n",
        "\n",
        "%cd /content/datasets/\n",
        "input_folder = \"inputs/raw\"\n",
        "basepath = os.getcwd()\n",
        "input_path = os.path.join(basepath, input_folder)\n",
        "\n",
        "%cd /content/datasets/outputs/exp1/\n",
        "output_folder = \"vae-raw\"\n",
        "basepath = os.getcwd()\n",
        "output_path = os.path.join(basepath, output_folder)\n",
        "os.mkdir(output_path)\n",
        "\n",
        "%cd /content/Bringing-Old-Photos-Back-to-Life\n",
        "!python run.py --input_folder /content/datasets/inputs/raw/ --output_folder /content/datasets/outputs/exp1/vae-raw/ --GPU -1"
      ],
      "metadata": {
        "id": "adwreGIvUIlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ISP/RAW ---> GFPGAN**"
      ],
      "metadata": {
        "id": "9ErqWVsMqRaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Dealing with clean data from ISP\n",
        "\n",
        "%cd /content/datasets/\n",
        "input_folder = \"inputs/clean\"\n",
        "basepath = os.getcwd()\n",
        "input_path = os.path.join(basepath, input_folder)\n",
        "\n",
        "%cd /content/datasets/outputs/exp1/\n",
        "output_folder = \"gfpgan-clean\"\n",
        "basepath = os.getcwd()\n",
        "output_path = os.path.join(basepath, output_folder)\n",
        "os.mkdir(output_path)\n",
        "\n",
        "%cd /content/GFPGAN/\n",
        "!python inference_gfpgan.py -i  /content/datasets/inputs/clean/ -o /content/datasets/outputs/exp1/gfpgan-clean/ -v 1.3 -s 2 --bg_upsampler realesrgan\n",
        "\n",
        "# Dealing with Raw Data\n",
        "\n",
        "%cd /content/datasets/\n",
        "input_folder = \"inputs/raw\"\n",
        "basepath = os.getcwd()\n",
        "input_path = os.path.join(basepath, input_folder)\n",
        "\n",
        "%cd /content/datasets/outputs/exp1/\n",
        "output_folder = \"gfpgan-raw\"\n",
        "basepath = os.getcwd()\n",
        "output_path = os.path.join(basepath, output_folder)\n",
        "os.mkdir(output_path)\n",
        "\n",
        "%cd /content/GFPGAN/\n",
        "!python inference_gfpgan.py -i  /content/datasets/inputs/raw/ -o /content/datasets/outputs/exp1/gfpgan-raw/ -v 1.3 -s 2 --bg_upsampler realesrgan\n"
      ],
      "metadata": {
        "id": "-nvSjtrexrfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 2**\n",
        "\n",
        "We are feeding the ouputs of each of the models into the other model "
      ],
      "metadata": {
        "id": "cV8obaKtGVRT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Raw-GFPGAN/ISP-GFPGAN --> VAE**"
      ],
      "metadata": {
        "id": "xqDMwxTpGvTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Dealing with clean data from ISP\n",
        "\n",
        "%cd /content/datasets/outputs/\n",
        "input_folder = \"exp1/gfpgan-clean/restored_imgs\"\n",
        "basepath = os.getcwd()\n",
        "input_path = os.path.join(basepath, input_folder)\n",
        "\n",
        "%cd /content/datasets/outputs/exp2/\n",
        "output_folder = \"vae-clean\"\n",
        "basepath = os.getcwd()\n",
        "output_path = os.path.join(basepath, output_folder)\n",
        "os.mkdir(output_path)\n",
        "\n",
        "%cd /content/Bringing-Old-Photos-Back-to-Life\n",
        "!python run.py --input_folder /content/datasets/outputs/exp1/gfpgan-clean/restored_imgs/ --output_folder /content/datasets/outputs/exp2/vae-clean/ --GPU -1\n",
        "\n",
        "# Dealing with Raw Data\n",
        "\n",
        "%cd /content/datasets/outputs/\n",
        "input_folder = \"exp1/gfpgan-raw/restored_imgs\"\n",
        "basepath = os.getcwd()\n",
        "input_path = os.path.join(basepath, input_folder)\n",
        "\n",
        "%cd /content/datasets/outputs/exp2/\n",
        "output_folder = \"vae-raw\"\n",
        "basepath = os.getcwd()\n",
        "output_path = os.path.join(basepath, output_folder)\n",
        "os.mkdir(output_path)\n",
        "\n",
        "%cd /content/Bringing-Old-Photos-Back-to-Life\n",
        "!python run.py --input_folder /content/datasets/outputs/exp1/gfpgan-raw/restored_imgs/ --output_folder /content/datasets/outputs/exp2/vae-raw/ --GPU -1"
      ],
      "metadata": {
        "id": "jl_4GWXEGjjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Raw-VAE/ISP-VAE --> GFPGAN**"
      ],
      "metadata": {
        "id": "-AWP0CMMG-_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Dealing with clean data from ISP\n",
        "\n",
        "%cd /content/datasets/outputs/\n",
        "input_folder = \"exp1/vae-clean/final_output\"\n",
        "basepath = os.getcwd()\n",
        "input_path = os.path.join(basepath, input_folder)\n",
        "\n",
        "%cd /content/datasets/outputs/exp2/\n",
        "output_folder = \"gfpgan-clean\"\n",
        "basepath = os.getcwd()\n",
        "output_path = os.path.join(basepath, output_folder)\n",
        "os.mkdir(output_path)\n",
        "\n",
        "%cd /content/GFPGAN/\n",
        "!python inference_gfpgan.py -i  /content/datasets/outputs/exp1/vae-clean/final_output/ -o /content/datasets/outputs/exp2/gfpgan-clean/ -v 1.3 -s 2 --bg_upsampler realesrgan\n",
        "\n",
        "# Dealing with Raw Data\n",
        "\n",
        "%cd /content/datasets/outputs/\n",
        "input_folder = \"exp1/vae-raw/final_output\"\n",
        "basepath = os.getcwd()\n",
        "input_path = os.path.join(basepath, input_folder)\n",
        "\n",
        "%cd /content/datasets/outputs/exp2/\n",
        "output_folder = \"gfpgan-raw\"\n",
        "basepath = os.getcwd()\n",
        "output_path = os.path.join(basepath, output_folder)\n",
        "os.mkdir(output_path)\n",
        "\n",
        "%cd /content/GFPGAN/\n",
        "!python inference_gfpgan.py -i  /content/datasets/outputs/exp1/vae-raw/final_output/ -o /content/datasets/outputs/exp2/gfpgan-raw/ -v 1.3 -s 2 --bg_upsampler realesrgan\n"
      ],
      "metadata": {
        "id": "jJlyL2M6HKhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/datasets /content/drive/MyDrive/Notebooks"
      ],
      "metadata": {
        "id": "bhgwz3t4PUpA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "# import eval_pred\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from torchmetrics import PeakSignalNoiseRatio\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def image2tensor(image):\n",
        "  \"\"\"\n",
        "  This function takes the path to an image and convert it into a tensor\n",
        "  \"\"\"\n",
        "  image = Image.open(image)\n",
        "  transform = transforms.Compose([\n",
        "      transforms.PILToTensor()\n",
        "  ])\n",
        "  img_tensor = transform(image)\n",
        "  return img_tensor\n",
        "\n",
        "def psnr(generated, input_img):\n",
        "  psnr = PeakSignalNoiseRatio()\n",
        "  preds = torch.tensor(image2tensor(generated))\n",
        "  target = torch.tensor(image2tensor(input_img))\n",
        "  if(target.size() != preds.size()):\n",
        "    preds = F.interpolate(preds, size=target.size())\n",
        "  psnr_val = psnr(preds, target)\n",
        "  return psnr_val.to_numpy()\n",
        "\n",
        "#Evaluate the PSNR of generated image\n",
        "raw_img = '/content/datasets/noisy/celeba-no-noise/Heng_Fan.png'\n",
        "gen_img = '/content/datasets/clean/vae/final_output/Heng_Fan.png'\n",
        "gfpgan_eval = psnr(raw_img, gen_img)"
      ],
      "metadata": {
        "id": "-7lq8G6OxCi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SSIM\n",
        "import math\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def ssim(img1, img2):\n",
        "    C1 = (0.01 * 255)**2\n",
        "    C2 = (0.03 * 255)**2\n",
        "\n",
        "    img1 = img1.astype(np.float64)\n",
        "    img2 = img2.astype(np.float64)\n",
        "    kernel = cv2.getGaussianKernel(11, 1.5)\n",
        "    window = np.outer(kernel, kernel.transpose())\n",
        "\n",
        "    mu1 = cv2.filter2D(img1, -1, window)[5:-5, 5:-5]  # valid\n",
        "    mu2 = cv2.filter2D(img2, -1, window)[5:-5, 5:-5]\n",
        "    mu1_sq = mu1**2\n",
        "    mu2_sq = mu2**2\n",
        "    mu1_mu2 = mu1 * mu2\n",
        "    sigma1_sq = cv2.filter2D(img1**2, -1, window)[5:-5, 5:-5] - mu1_sq\n",
        "    sigma2_sq = cv2.filter2D(img2**2, -1, window)[5:-5, 5:-5] - mu2_sq\n",
        "    sigma12 = cv2.filter2D(img1 * img2, -1, window)[5:-5, 5:-5] - mu1_mu2\n",
        "\n",
        "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) *\n",
        "                                                            (sigma1_sq + sigma2_sq + C2))\n",
        "    return ssim_map.mean()\n",
        "\n",
        "\n",
        "def calculate_ssim(img1, img2):\n",
        "    '''calculate SSIM\n",
        "    the same outputs as MATLAB's\n",
        "    img1, img2: [0, 255]\n",
        "    '''\n",
        "    if not img1.shape == img2.shape:\n",
        "        raise ValueError('Input images must have the same dimensions.')\n",
        "    if img1.ndim == 2:\n",
        "        return ssim(img1, img2)\n",
        "    elif img1.ndim == 3:\n",
        "        if img1.shape[2] == 3:\n",
        "            ssims = []\n",
        "            for i in range(3):\n",
        "                ssims.append(ssim(img1, img2))\n",
        "            return np.array(ssims).mean()\n",
        "        elif img1.shape[2] == 1:\n",
        "            return ssim(np.squeeze(img1), np.squeeze(img2))\n",
        "    else:\n",
        "        raise ValueError('Wrong input image dimensions.')"
      ],
      "metadata": {
        "id": "SJwQDllsRM_f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}